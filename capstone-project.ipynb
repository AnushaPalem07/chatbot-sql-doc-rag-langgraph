{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall -qqy jupyterlab\n!pip install -U -q \"google-genai==1.7.0\"\n!pip install -qU 'langgraph==0.3.21' 'langchain-google-genai==2.1.2' 'langgraph-prebuilt==0.1.7'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -qU \"chromadb==0.6.3\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:33:54.508681Z","iopub.execute_input":"2025-04-14T04:33:54.509077Z","iopub.status.idle":"2025-04-14T04:34:39.211157Z","shell.execute_reply.started":"2025-04-14T04:33:54.509036Z","shell.execute_reply":"2025-04-14T04:34:39.209722Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Declaring required libraies","metadata":{}},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\nfrom IPython.display import Image,display,HTML,Markdown\nimport numpy as np\nimport pandas as pd\nfrom kaggle_secrets import UserSecretsClient\nimport re,json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:34:39.213336Z","iopub.execute_input":"2025-04-14T04:34:39.213669Z","iopub.status.idle":"2025-04-14T04:34:41.309059Z","shell.execute_reply.started":"2025-04-14T04:34:39.213638Z","shell.execute_reply":"2025-04-14T04:34:41.308030Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"GOOGLE_API_KEY = UserSecretsClient().get_secret(\"Capstone_API_KEY\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:34:41.310613Z","iopub.execute_input":"2025-04-14T04:34:41.311335Z","iopub.status.idle":"2025-04-14T04:34:41.401497Z","shell.execute_reply.started":"2025-04-14T04:34:41.311290Z","shell.execute_reply":"2025-04-14T04:34:41.400290Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Ingestion\n\n    \n\n*1. We are ingesting the data in structured and unstructured data.      \n 2. Structured data - SQL and unstructured data - Documents*\n\n","metadata":{}},{"cell_type":"markdown","source":"## 1. SQL Data","metadata":{}},{"cell_type":"code","source":"%load_ext sql\n%sql sqlite:///job_profiles.db","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:34:41.402942Z","iopub.execute_input":"2025-04-14T04:34:41.403473Z","iopub.status.idle":"2025-04-14T04:34:42.390519Z","shell.execute_reply.started":"2025-04-14T04:34:41.403430Z","shell.execute_reply":"2025-04-14T04:34:42.389408Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sqlite3\n\ndb_file = \"job_profiles.db\"\ndb_conn = sqlite3.connect(db_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:34:42.391728Z","iopub.execute_input":"2025-04-14T04:34:42.392158Z","iopub.status.idle":"2025-04-14T04:34:42.398037Z","shell.execute_reply.started":"2025-04-14T04:34:42.392093Z","shell.execute_reply":"2025-04-14T04:34:42.396709Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%sql\n-- Creating job profiles table where it contains the job role, years of experience and skills\n\nCREATE TABLE IF NOT EXISTS jobProfiles(\n    role VARCHAR(255) NOT NULL,\n    skills TEXT\n) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:34:42.399352Z","iopub.execute_input":"2025-04-14T04:34:42.399791Z","iopub.status.idle":"2025-04-14T04:34:42.448794Z","shell.execute_reply.started":"2025-04-14T04:34:42.399752Z","shell.execute_reply":"2025-04-14T04:34:42.447364Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%sql\nINSERT INTO jobProfiles(role, skills) \nVALUES \n  ('GenAI Engineer', 'AI, ML, Python'),\n  ('Data Scientist', 'Python, Statistics, SQL, Machine Learning'),\n  ('MLOps Engineer', 'Docker, Kubernetes, CI/CD, TensorFlow Serving'),\n  ('Python Developer','Python');","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:34:42.451797Z","iopub.execute_input":"2025-04-14T04:34:42.452098Z","iopub.status.idle":"2025-04-14T04:34:42.471883Z","shell.execute_reply.started":"2025-04-14T04:34:42.452070Z","shell.execute_reply":"2025-04-14T04:34:42.470749Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Defining tools for SQL","metadata":{}},{"cell_type":"code","source":"def delete_table(table_name: str):\n    cursor = db_conn.cursor()\n    \"\"\"Deleting a table from the database.\"\"\"\n    cursor.execute(f\"DROP TABLE IF EXISTS {table_name};\")\n    db_conn.commit()\n    return f\"Table '{table_name}' has been deleted.\"  \ndef describe_table(table_name: str):\n    cursor = db_conn.cursor()\n    print(f' - DB CALL: describe_table({table_name})')\n    cursor.execute(f\"PRAGMA table_info({table_name});\")\n    # cursor.execute(f\"DESCRIBE {table_name}\");\n    schema = cursor.fetchall()\n    return [(col[1], col[2]) for col in schema]\n\ndef list_tables():\n    print(' - DB CALL: list_tables()')\n    cursor = db_conn.cursor()\n    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n    tables = cursor.fetchall()\n    return [t[0] for t in tables]\n\ndef execute_query(sqlQuery: str) -> str:\n    \"\"\"Execute a SQL query on the database.\"\"\"\n    print(f' - DB CALL: execute_query({sqlQuery})')\n    cursor = db_conn.cursor()\n    cursor.execute(sqlQuery)\n    return str(cursor.fetchall())\n# delete_table(\"jobProfiles\")\n# describe_table(\"jobProfiles\")\n# list_tables()\n# execute_query(\"SELECT * from jobProfiles\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:34:42.473897Z","iopub.execute_input":"2025-04-14T04:34:42.474246Z","iopub.status.idle":"2025-04-14T04:34:42.482636Z","shell.execute_reply.started":"2025-04-14T04:34:42.474217Z","shell.execute_reply":"2025-04-14T04:34:42.481526Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## LLM Prompt for SQL","metadata":{}},{"cell_type":"code","source":"## SQL Data Retrieval\ndb_tools = [describe_table,list_tables,execute_query]\n\nsql_prompt = \"\"\"\nYou are a helpful chatbot for a SQL database.\n\nYour task is to understand user questions, run SQL queries using available tools, and provide answers based on the data.\n\nIf a question is complex or multi-part, answer what you can using the data. If only partial info is available, \nrespond with what’s found — don’t mention what’s missing.\n\nTools:\n- execute_query: Run SQL queries. \n- describe_table: View table schema\n- list_tables: View table names\n\nGiven a user-provided role, check if the core keywords from the input are present anywhere within the full role names \nstored in our database. The match does not need to be exact. For example, if the user provides 'Gen AI', and the database \nhas 'Gen AI Engineer', consider it a match. Use case-insensitive partial matching and focus on keyword presence \nrather than exact string equality.\n\nRespond in this format:\n{ \"response\": \"your answer here\" }\n\nIf nothing is found:\n{ \"response\": \"I am unable to find that information\" }\n\nExample:\nUser: What are the skills required for GenAI engineer and explain me what is GenAI?\n\nResponse:\n{ \"response\": \"Skills required for GenAI Engineer are AI, ML, Python.\" }\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:43:51.331195Z","iopub.execute_input":"2025-04-14T04:43:51.331632Z","iopub.status.idle":"2025-04-14T04:43:51.337147Z","shell.execute_reply.started":"2025-04-14T04:43:51.331604Z","shell.execute_reply":"2025-04-14T04:43:51.335806Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Defining the LLM Model ","metadata":{}},{"cell_type":"code","source":"client = genai.Client(api_key=GOOGLE_API_KEY)\nchat = client.chats.create(\n    model=\"gemini-2.0-flash\",\n    config=types.GenerateContentConfig(\n        system_instruction=sql_prompt,\n        tools=db_tools,\n    ),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:44:01.275564Z","iopub.execute_input":"2025-04-14T04:44:01.275929Z","iopub.status.idle":"2025-04-14T04:44:01.412613Z","shell.execute_reply.started":"2025-04-14T04:44:01.275903Z","shell.execute_reply":"2025-04-14T04:44:01.411296Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Post-processing SQL output format","metadata":{}},{"cell_type":"code","source":"def post_processing_SQL_response(response):\n    raw_text = response.candidates[0].content.parts[0].text\n    print(f\"Response from the SQL database: {raw_text}\")\n    match = re.search(r'\\{.*\\}', raw_text)\n    if match:\n        json_part = match.group(0)\n        data = json.loads(json_part)\n        return data[\"response\"]\n    return \"Not able to get response. Try debugging the issue....\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:34:42.920024Z","iopub.execute_input":"2025-04-14T04:34:42.920328Z","iopub.status.idle":"2025-04-14T04:34:42.926028Z","shell.execute_reply.started":"2025-04-14T04:34:42.920296Z","shell.execute_reply":"2025-04-14T04:34:42.924748Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Validating the SQL info retrieval","metadata":{}},{"cell_type":"code","source":"resp = chat.send_message(\"What is RAG?\")\nresult = post_processing_SQL_response(resp)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:47:32.991797Z","iopub.execute_input":"2025-04-14T04:47:32.992126Z","iopub.status.idle":"2025-04-14T04:47:33.717474Z","shell.execute_reply.started":"2025-04-14T04:47:32.992100Z","shell.execute_reply":"2025-04-14T04:47:33.716203Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.Text Document","metadata":{}},{"cell_type":"markdown","source":"## Declaring documents","metadata":{}},{"cell_type":"code","source":"DOCUMENT1 = \"\"\"\nInterview questions for AI:\n\nQ1. What is Artificial Intelligence?\nA1. Artificial Intelligence is the simulation of human intelligence in machines that are programmed to think and learn.\n\nQ2. What are the main types of AI?\nA2. The types are: Reactive Machines, Limited Memory, Theory of Mind, and Self-aware AI.\n\nQ3. What is the difference between AI, ML, and Deep Learning?\nA3. AI is the broader concept of machines being intelligent, ML is a subset of AI focused on learning from data, and Deep Learning is a subset of ML using neural networks.\n\nQ4. What are some real-world applications of AI?\nA4. Examples include voice assistants (e.g. Siri), recommendation systems, autonomous vehicles, and chatbots.\n\nQ5. What is the Turing Test?\nA5. The Turing Test is a way to evaluate a machine’s ability to exhibit human-like intelligence.\n\nQ6. What is the difference between Narrow AI and General AI?\nA6. Narrow AI is designed for specific tasks, while General AI has the ability to perform any intellectual task that a human can.\n\nQ7. What are the main components of an AI system?\nA7. Components include learning, reasoning, problem-solving, perception, and language understanding.\n\nQ8. What is an intelligent agent in AI?\nA8. An intelligent agent is an autonomous entity which observes its environment and acts upon it to achieve goals.\n\nQ9. Explain the concept of state space in AI.\nA9. State space is the set of all possible states that can be reached in solving a problem.\n\nQ10. What is a heuristic function?\nA10. A heuristic function estimates the cost from the current state to the goal, guiding search algorithms.\n\n\"\"\"\nDOCUMENT2 = \"\"\"\n\nInterview questions for ML:\n\nQ1. What is Machine Learning?\nA1. Machine Learning is a subset of AI that enables machines to learn from data and make decisions without being explicitly programmed.\n\nQ2. What are the types of Machine Learning?\nA2. Supervised Learning, Unsupervised Learning, and Reinforcement Learning.\n\nQ3. What is the difference between Supervised and Unsupervised learning?\nA3. Supervised learning uses labeled data, while unsupervised learning uses unlabeled data to find hidden patterns.\n\nQ4. What is overfitting and underfitting?\nA4. Overfitting is when the model learns noise instead of the signal. Underfitting is when the model is too simple to capture the data's complexity.\n\nQ5. What is the bias-variance tradeoff?\nA5. It’s the balance between a model’s ability to generalize (low variance) and its accuracy (low bias).\n\nQ6. What are features and labels in ML?\nA6. Features are input variables, and labels are the output (target) variables the model learns to predict.\n\nQ7. What are precision, recall, and F1 score?\nA7. Precision: correct positives / predicted positives, Recall: correct positives / actual positives, F1 Score: harmonic mean of precision and recall.\n\nQ8. What is cross-validation?\nA8. Cross-validation is a technique to assess model performance by splitting the dataset into multiple training and testing sets.\n\nQ9. What is the purpose of the train/test split?\nA9. To evaluate model performance on unseen data by training on one subset and testing on another.\n\nQ10. Name a few popular ML algorithms.\nA10. Linear Regression, Logistic Regression, Decision Trees, SVM, K-Nearest Neighbors, Random Forests.\n\"\"\"\nDOCUMENT3 = \"\"\"\n\nInterview questions for Python:\n\nQ1. What are Python's key features?\nA1. Easy syntax, interpreted, dynamically typed, supports OOP, and has vast libraries.\n\nQ2. What is the difference between a list and a tuple?\nA2. Lists are mutable (changeable), while tuples are immutable.\n\nQ3. What are Python's data types?\nA3. Common types include int, float, str, list, tuple, dict, set, bool.\n\nQ4. What is the difference between `is` and `==`?\nA4. `is` checks identity (memory location), `==` checks value equality.\n\nQ5. What are *args and **kwargs?\nA5. *args allows variable number of positional arguments, **kwargs allows variable number of keyword arguments.\n\nQ6. What are Python decorators?\nA6. Decorators are functions that modify the behavior of other functions without changing their code.\n\nQ7. How is memory managed in Python?\nA7. Python uses automatic memory management via reference counting and garbage collection.\n\nQ8. What is a lambda function?\nA8. A lambda is an anonymous, one-line function defined using the keyword `lambda`.\n\nQ9. What is the use of `self` in Python classes?\nA9. `self` refers to the current instance of the class and is used to access its variables and methods.\n\nQ10. What are list comprehensions?\nA10. List comprehensions provide a concise way to create lists using a single line of code.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:34:45.892898Z","iopub.execute_input":"2025-04-14T04:34:45.893212Z","iopub.status.idle":"2025-04-14T04:34:45.899832Z","shell.execute_reply.started":"2025-04-14T04:34:45.893185Z","shell.execute_reply":"2025-04-14T04:34:45.898155Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Combining all docs in one document","metadata":{}},{"cell_type":"code","source":"topics = [\"ai\", \"ml\", \"python\"]\ndocs = {\n    \"ai\": DOCUMENT1,\n    \"ml\": DOCUMENT2,\n    \"python\": DOCUMENT3\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:34:45.901206Z","iopub.execute_input":"2025-04-14T04:34:45.901666Z","iopub.status.idle":"2025-04-14T04:34:45.983785Z","shell.execute_reply.started":"2025-04-14T04:34:45.901626Z","shell.execute_reply":"2025-04-14T04:34:45.982406Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Declaring nessesary libraries","metadata":{}},{"cell_type":"code","source":"from chromadb import Documents, EmbeddingFunction, Embeddings\nfrom google.api_core import retry\nfrom google.genai import types\nimport chromadb\nimport json\nimport re","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:34:45.984935Z","iopub.execute_input":"2025-04-14T04:34:45.985540Z","iopub.status.idle":"2025-04-14T04:34:46.908830Z","shell.execute_reply.started":"2025-04-14T04:34:45.985434Z","shell.execute_reply":"2025-04-14T04:34:46.907649Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Converting documents into embeddings","metadata":{}},{"cell_type":"code","source":"## Document Data Retrieval\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n\nclass GeminiEmbeddingFunction(EmbeddingFunction):\n    isDocumentEmbeddings = True\n    @retry.Retry(predicate=is_retriable)\n    def __call__(self, input: Documents) -> Embeddings:\n        if self.isDocumentEmbeddings:\n            embedding_task = \"retrieval_document\"\n        else:\n            embedding_task = \"retrieval_query\"\n        response = client.models.embed_content(\n            model=\"models/text-embedding-004\",\n            contents=input,\n            config=types.EmbedContentConfig(\n                task_type=embedding_task,\n            ),\n        )\n        return [e.values for e in response.embeddings]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:34:46.909903Z","iopub.execute_input":"2025-04-14T04:34:46.910507Z","iopub.status.idle":"2025-04-14T04:34:47.044803Z","shell.execute_reply.started":"2025-04-14T04:34:46.910476Z","shell.execute_reply":"2025-04-14T04:34:47.043503Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Storing embeddings in vector databases.","metadata":{}},{"cell_type":"code","source":"DB_NAME = \"googlecardb\"\nembed_fn = GeminiEmbeddingFunction()\nembed_fn.isDocumentEmbeddings = True\nchroma_client = chromadb.Client()\ndb = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n# all_ids = db.get()['ids']\n# db.delete(ids=all_ids)\n\ndb.add(\n    documents=[docs[t] for t in topics],\n    ids=topics,\n    metadatas=[\n    {\"topic\": \"ai\"},\n    {\"topic\": \"ml\"},\n    {\"topic\": \"python\"}\n  ]\n)\n\ndb.count()\n# print(db.get()['ids'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:34:47.045888Z","iopub.execute_input":"2025-04-14T04:34:47.046176Z","iopub.status.idle":"2025-04-14T04:34:47.814474Z","shell.execute_reply.started":"2025-04-14T04:34:47.046153Z","shell.execute_reply":"2025-04-14T04:34:47.812656Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Documents Retrieval","metadata":{}},{"cell_type":"code","source":"def detect_topic(user_query):\n    topics = [\"python\", \"ai\", \"ml\"]\n    return [topic for topic in topics if topic in user_query.lower()]\ndef retrieval_documents(query,threshold=0.8,sql_answer=\"\"):\n    print(threshold)\n    embed_fn.isDocumentEmbeddings = False\n    topics = detect_topic(f\"Query:{query}. SQL Response:{sql_answer}\")\n    print(topics)\n    final_results = []\n    for topic in topics:\n        result = db.query(\n            query_texts=[query],\n            n_results=3,\n            where={\"topic\": topic}  # Assumes you added metadata: {\"topic\": \"python\"} etc.\n        )\n        final_results.extend(zip(result['documents'][0], result['distances'][0]))\n    # print(final_results)\n    filtered_results = [(doc, dist) for doc, dist in final_results if dist <= threshold]\n    # print(filtered_results)\n    return filtered_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:34:47.815706Z","iopub.execute_input":"2025-04-14T04:34:47.816049Z","iopub.status.idle":"2025-04-14T04:34:47.823559Z","shell.execute_reply.started":"2025-04-14T04:34:47.816021Z","shell.execute_reply":"2025-04-14T04:34:47.822199Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Generate LLM Response","metadata":{}},{"cell_type":"code","source":"def get_llm_response(query,retrieved_documents,sql_answer):\n    if sql_answer == \"I am unable to find that information\" and not retrieved_documents:\n        return \"No relevant documents found for your query.\"\n    retrieved_documents.sort(key=lambda x: x[1])\n    res = \"\\n\\n\".join(doc for doc, _ in retrieved_documents)\n    prompt = f\"\"\"\n        You are a helpful and informative assistant that answers user questions by combining insights from structured SQL data and unstructured document embeddings.\n        \n        Your goal is to provide a clear, complete, and friendly response using the following context:\n        - SQL Info (if available): Use it to extract concrete, structured facts.\n        - Embedding Search Results (cosine similarity): Use them to supplement or enhance the answer with richer context.\n        - If the data seems partial or only part of the question is answered, still try to provide a helpful response based on available context.\n        - Your audience is non-technical. Keep your tone friendly and easy to understand, breaking down any technical jargon.\n        \n        QUESTION:\n        {query}\n        \n        SQL INFO:\n        {sql_answer}\n        \n        DOCUMENTS FROM COSINE SIMILARITY SEARCH:\n        {retrieved_documents}\n        \n        Now, using the above context, provide a complete and concise answer.\n        If you have enough information, include examples or details from the documents.\n        If the SQL result already answers the question well, summarize or explain it clearly.\n        \n        Always return your final answer in this format:\n        {{ \"response\" : \"your answer here\" }}\n        \"\"\"\n    answer = client.models.generate_content(\n                model=\"gemini-2.0-flash\",\n                contents=prompt)\n    res = answer.text\n    res = re.sub(r\"^```json\\s*|\\s*```$\", \"\", res.strip(), flags=re.IGNORECASE | re.MULTILINE)\n    try:\n        if res:\n            json_obj = json.loads(res)\n            return json_obj[\"response\"]\n        else:\n            print(\"Empty response.\")\n    except json.JSONDecodeError as e:\n        print(\"Invalid JSON:\", e)\n        print(\"Raw cleaned response:\", repr(res))\n    # res = answer.text\n    # try:\n    #     if res.strip(): \n    #         json_obj = json.loads(res)\n    #         return json_obj[\"response\"]\n    #     else:\n    #         print(\"Empty response text.\")\n    # except json.JSONDecodeError as e:\n    #     print(\"Invalid JSON:\", e)\n    return res\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:47:47.104853Z","iopub.execute_input":"2025-04-14T04:47:47.105193Z","iopub.status.idle":"2025-04-14T04:47:47.113362Z","shell.execute_reply.started":"2025-04-14T04:47:47.105168Z","shell.execute_reply":"2025-04-14T04:47:47.112072Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Declaring Langraph libraries","metadata":{}},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\nfrom typing import Annotated\nfrom typing_extensions import TypedDict\nfrom langgraph.graph.message import add_messages","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:34:47.854083Z","iopub.execute_input":"2025-04-14T04:34:47.854504Z","iopub.status.idle":"2025-04-14T04:34:48.491359Z","shell.execute_reply.started":"2025-04-14T04:34:47.854467Z","shell.execute_reply":"2025-04-14T04:34:48.489919Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Defining the state schema","metadata":{}},{"cell_type":"code","source":"#Define the state \nclass state_schema(TypedDict):\n    messages : Annotated[list,add_messages]\n    query : str\n    sql_response: str\n    retrieved_documents: list[str]\n    final_answer : str\n    finished : bool\n\nwelcome_msg = \"Welcome to the Interview Prep regarding the job role.\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:34:48.492723Z","iopub.execute_input":"2025-04-14T04:34:48.493078Z","iopub.status.idle":"2025-04-14T04:34:48.498925Z","shell.execute_reply.started":"2025-04-14T04:34:48.493043Z","shell.execute_reply":"2025-04-14T04:34:48.497596Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Declaring functions for the Nodes","metadata":{}},{"cell_type":"code","source":"from langchain_google_genai import ChatGoogleGenerativeAI\nfrom langgraph.graph import StateGraph,START,END\nfrom langchain_core.messages.ai import AIMessage\n\nllm = ChatGoogleGenerativeAI(model =\"gemini-2.0-flash\")\n\n#define the functions \ndef conditional_edge(state_schema) -> state_schema:\n    if state_schema.get(\"finished\", True):\n        return END  \n    return \"input_query\"   \ndef input_query(state_schema) -> state_schema:  \n    if not state_schema[\"messages\"]:\n        state_schema[\"query\"] = \"\"\n        state_schema[\"sql_response\"] = \"\"\n        state_schema[\"retrieved_documents\"] = []\n        state_schema[\"final_answer\"] = \"\"\n        state_schema[\"finished\"] = False\n        state_schema[\"messages\"] = [AIMessage(content=welcome_msg)]  \n        print(f\"Bot: {welcome_msg}\")\n    return state_schema\ndef sql_info(state_schema) -> state_schema:\n    if state_schema[\"messages\"]:\n        if state_schema[\"final_answer\"] != \"\":\n            print(\"Bot:\",state_schema[\"final_answer\"])\n        user_input = input(\"User: \")\n        state_schema[\"query\"] = user_input\n        exit_words = {\"q\", \"quit\", \"exit\", \"goodbye\"}\n        print(f\"Exit validation: {user_input.strip().lower() in exit_words }\")\n        if user_input.strip().lower() in exit_words:\n            print(\"user wants to exit from the chat.\")\n            state_schema[\"finished\"] = True\n            return state_schema\n        state_schema[\"messages\"] = [(\"user\", user_input)]\n        resp = chat.send_message(user_input)\n        result = post_processing_SQL_response(resp)\n        # print(result)\n        state_schema[\"sql_response\"] = result\n        state_schema[\"messages\"] = [(\"ai\",result)] \n    return state_schema \n    \ndef retrieve_documents(state_schema) -> state_schema:\n    query = state_schema[\"query\"]\n    sql_response = state_schema[\"sql_response\"]\n    if sql_response == \"I am unable to find that information\":\n        retrieved_documents = retrieval_documents(query)    \n    else:\n        retrieved_documents = retrieval_documents(query,0.96,state_schema[\"sql_response\"])\n    state_schema[\"retrieved_documents\"] = retrieved_documents\n    # print(\"*\"*20)\n    # print(f\"final result: {final_result}\")\n    # print(\"*\"*20)\n    return state_schema\ndef get_final_result(state_schema) -> state_schema:\n    query = state_schema[\"query\"]\n    sql_response = state_schema[\"sql_response\"]\n    retrieved_documents = state_schema[\"retrieved_documents\"]\n    result = get_llm_response(query,retrieved_documents,sql_response)\n    state_schema[\"final_answer\"] = result\n    return state_schema","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:34:48.503197Z","iopub.execute_input":"2025-04-14T04:34:48.503582Z","iopub.status.idle":"2025-04-14T04:34:58.242996Z","shell.execute_reply.started":"2025-04-14T04:34:48.503551Z","shell.execute_reply":"2025-04-14T04:34:58.241822Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Build graph and mention the nodes and edges","metadata":{}},{"cell_type":"code","source":"graph = StateGraph(state_schema)\ngraph.add_node(\"input_query\",input_query)\ngraph.add_node(\"sql_info\",sql_info)\ngraph.add_node(\"retrieve_documents\",retrieve_documents)\ngraph.add_node(\"get_final_result\",get_final_result)\n\ngraph.add_edge(START,\"input_query\")\ngraph.add_edge(\"input_query\",\"sql_info\")\ngraph.add_edge(\"sql_info\",\"retrieve_documents\")\ngraph.add_edge(\"retrieve_documents\",\"get_final_result\")\ngraph.add_conditional_edges(\"get_final_result\", conditional_edge)\n\nchatGraph = graph.compile()","metadata":{"execution":{"iopub.status.busy":"2025-04-14T04:34:58.244450Z","iopub.execute_input":"2025-04-14T04:34:58.244821Z","iopub.status.idle":"2025-04-14T04:34:58.259792Z","shell.execute_reply.started":"2025-04-14T04:34:58.244789Z","shell.execute_reply":"2025-04-14T04:34:58.258307Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Display the graph","metadata":{}},{"cell_type":"code","source":"from IPython.display import display,Image\n# Image(chatGraph.get_graph().draw_mermaid_png())\nprint(chatGraph.get_graph().draw_mermaid())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:35:42.605855Z","iopub.execute_input":"2025-04-14T04:35:42.606206Z","iopub.status.idle":"2025-04-14T04:35:42.613132Z","shell.execute_reply.started":"2025-04-14T04:35:42.606180Z","shell.execute_reply":"2025-04-14T04:35:42.611662Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Initializing the chatbot","metadata":{}},{"cell_type":"code","source":"state = chatGraph.invoke({\"messages\": []})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T04:47:52.862196Z","iopub.execute_input":"2025-04-14T04:47:52.862604Z","iopub.status.idle":"2025-04-14T04:48:54.227125Z","shell.execute_reply.started":"2025-04-14T04:47:52.862574Z","shell.execute_reply":"2025-04-14T04:48:54.226122Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}